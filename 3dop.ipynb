{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.nn.functional import conv_transpose2d as tran\n",
    "from torch.nn.functional import conv2d as libConv2d\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = torch.randn(1, 1, 2, 2)  \n",
    "w = torch.randn(1, 1, 2, 2)  \n",
    "out = tran(in_data, w, stride=1, padding=0, dilation=1)\n",
    "stride = 1\n",
    "padding = 0\n",
    "dilattion = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def conv2d_transposed(in_data, in_channels, out_channels, kernel_size,\n",
    "                      stride=1, padding=0, output_padding=0, dilation=1,\n",
    "                      bias=True, padding_mode='zeros'):\n",
    "    # Проверка и создание bias\n",
    "    if bias:\n",
    "        bias_val = np.random.rand(out_channels)\n",
    "    else:\n",
    "        bias_val = np.zeros(out_channels)\n",
    "    # Проверка padding_mode\n",
    "    if padding_mode != 'zeros':\n",
    "        raise ValueError('only \"zeros\" padding_mode in ConvTranspose2d')\n",
    "    # Генерация ядра\n",
    "    if type(kernel_size) == tuple:\n",
    "        weights = np.random.rand(out_channels, in_channels, kernel_size[0], kernel_size[1])\n",
    "    elif type(kernel_size) == int:\n",
    "        weights = np.random.rand(out_channels, in_channels, kernel_size, kernel_size)\n",
    "    else:\n",
    "        raise ValueError('Invalid kernel_size type')\n",
    "    # Транспонированная свертка вручную\n",
    "    result_tensor = []\n",
    "    for out_channel_idx in range(out_channels):\n",
    "        feature_map = np.zeros(((in_data.shape[2] - 1) * stride + dilation * (kernel_size - 1) + 1,\n",
    "                                (in_data.shape[3] - 1) * stride + dilation * (kernel_size - 1) + 1))\n",
    "        for in_channel_idx in range(in_channels):\n",
    "            for i in range(0, in_data.shape[2]):\n",
    "                for j in range(0, in_data.shape[3]):\n",
    "                    value = in_data[0, in_channel_idx, i, j]\n",
    "                    product = value * weights[out_channel_idx, in_channel_idx]\n",
    "                    zero_tensor = np.zeros(((weights.shape[2] - 1) * dilation + 1, (weights.shape[3] - 1) * dilation + 1))\n",
    "\n",
    "                    for a in range(0, zero_tensor.shape[0], dilation):\n",
    "                        for b in range(0, zero_tensor.shape[1], dilation):\n",
    "                            zero_tensor[a, b] = product[a // dilation, b // dilation]\n",
    "\n",
    "                    res = np.add(zero_tensor, feature_map[i * stride:i * stride + (weights.shape[2] - 1) * dilation + 1,\n",
    "                                                   j * stride:j * stride + (weights.shape[3] - 1) * dilation + 1])\n",
    "                    feature_map[i * stride:i * stride + (weights.shape[2] - 1) * dilation + 1,\n",
    "                    j * stride:j * stride + (weights.shape[3] - 1) * dilation + 1] = res\n",
    "        result_tensor.append(np.add(feature_map, bias_val[out_channel_idx]))\n",
    "    for t in range(len(result_tensor)):\n",
    "        if output_padding > 0:\n",
    "            result_tensor[t] = np.pad(result_tensor[t], ((0, output_padding), (0, output_padding)), 'constant', constant_values=0)\n",
    "        result_tensor[t] = result_tensor[t][padding:-padding, padding:-padding]\n",
    "    return result_tensor, weights, bias_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def compare(tensor, in_channels, out_channels, kernel_size, stride, padding, output_padding, dilation, bias=True, padding_mode='zeros'):\n",
    "    my_res, my_kernel, my_bias_val = conv2d_transposed(\n",
    "        tensor,\n",
    "        in_channels=in_channels, out_channels=out_channels,\n",
    "        kernel_size=kernel_size, stride=stride,\n",
    "        padding=padding, output_padding=output_padding,\n",
    "        dilation=dilation, bias=bias,\n",
    "        padding_mode=padding_mode,\n",
    "    )\n",
    "\n",
    "    torch_function = torch.nn.ConvTranspose2d(\n",
    "        in_channels=in_channels, out_channels=out_channels,\n",
    "        kernel_size=kernel_size, stride=stride,\n",
    "        padding=padding, output_padding=output_padding,\n",
    "        dilation=dilation, bias=bias,\n",
    "        padding_mode=padding_mode,\n",
    "    )\n",
    "    torch_function.weight.data = torch.Tensor(my_kernel)\n",
    "    torch_function.bias.data = torch.Tensor(my_bias_val)\n",
    "\n",
    "    my_result = str(np.round([tensor.tolist() for tensor in my_res], 2))\n",
    "    torch_result = str(np.round(torch_function(torch.Tensor(tensor)).data.numpy(), 2))\n",
    "    return my_result == torch_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "tensor = np.random.randn(1, 1, 4, 4)\n",
    "in_channels = 1\n",
    "out_channels = 1\n",
    "kernel_size = 2\n",
    "stride = 1\n",
    "padding = 0\n",
    "output_padding = 0\n",
    "dilation = 1\n",
    "result = compare(tensor, in_channels, out_channels, kernel_size, stride, padding, output_padding, dilation)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "tensor = np.random.randn(1, 1, 5, 5)\n",
    "in_channels = 1\n",
    "out_channels = 1\n",
    "kernel_size = 3\n",
    "stride = 2\n",
    "padding = 1\n",
    "output_padding = 1\n",
    "dilation = 1\n",
    "result = compare(tensor, in_channels, out_channels, kernel_size, stride, padding, output_padding, dilation)\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def custom_transpose_conv2d(\n",
    "    input_tensor, in_channels, out_channels, kernel_size,\n",
    "    transp_stride=1, padding=0, dilation=1, use_bias=True, padding_mode='zeros'\n",
    "):\n",
    "    pad = (kernel_size - 1) * dilation - padding\n",
    "\n",
    "    input_tensor_padded = np.pad(input_tensor, ((0, 0), (pad, pad), (pad, pad)), mode=padding_mode)\n",
    "\n",
    "    \n",
    "    if use_bias:\n",
    "        bias_val = np.random.rand(out_channels)\n",
    "    else:\n",
    "        bias_val = np.zeros(out_channels)\n",
    "\n",
    "    weights = np.random.rand(out_channels, in_channels, kernel_size, kernel_size)\n",
    "\n",
    "    output_size = (\n",
    "        (input_tensor.shape[1] - 1) * transp_stride + dilation * (kernel_size - 1) + 1,\n",
    "        (input_tensor.shape[2] - 1) * transp_stride + dilation * (kernel_size - 1) + 1,\n",
    "    )\n",
    "\n",
    "    result_tensor = np.zeros((out_channels,) + output_size)\n",
    "\n",
    "    for l in range(out_channels):\n",
    "        for c in range(in_channels):\n",
    "            for i in range(0, input_tensor.shape[1]):\n",
    "                for j in range(0, input_tensor.shape[2]):\n",
    "                    val = input_tensor[c, i, j]\n",
    "                    proizv = val * weights[l, c]\n",
    "                    zero_tensor = np.zeros(\n",
    "                        (weights.shape[2] - 1) * dilation + 1, (weights.shape[3] - 1) * dilation + 1\n",
    "                    )\n",
    "                    for a in range(0, zero_tensor.shape[0], dilation):\n",
    "                        for b in range(0, zero_tensor.shape[1], dilation):\n",
    "                            zero_tensor[a, b] = proizv[a // dilation, b // dilation]\n",
    "\n",
    "                    result_tensor[l, i * transp_stride : i * transp_stride + zero_tensor.shape[0], \n",
    "                                 j * transp_stride : j * transp_stride + zero_tensor.shape[1]] += zero_tensor\n",
    "\n",
    "        result_tensor[l] += bias_val[l]\n",
    "\n",
    "    return result_tensor, weights, bias_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compare_with_torch(input_tensor, in_channels, out_channels, kernel_size, transp_stride=1, padding=0, dilation=1, use_bias=True, padding_mode='zeros'):\n",
    "    result_custom, weights_custom, bias_custom = custom_transpose_conv2d(\n",
    "        input_tensor, in_channels, out_channels, kernel_size,\n",
    "        transp_stride, padding, dilation, use_bias, padding_mode\n",
    "    )\n",
    "\n",
    "    conv_transpose = torch.nn.ConvTranspose2d(\n",
    "        in_channels, out_channels, kernel_size,\n",
    "        stride=transp_stride, padding=padding, dilation=dilation, bias=use_bias, padding_mode=padding_mode\n",
    "    )\n",
    "    conv_transpose.weight.data = weights_custom\n",
    "    conv_transpose.bias.data = bias_custom\n",
    "\n",
    "    result_torch = conv_transpose(torch.tensor(input_tensor)).data.numpy()\n",
    "\n",
    "    return np.allclose(result_custom, result_torch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "input_tensor1 = np.random.rand(1, 4, 4, 4)  \n",
    "in_channels1 = 3\n",
    "out_channels1 = 2\n",
    "kernel_size1 = 3\n",
    "result_comparison1 = compare_with_torch(input_tensor1, in_channels1, out_channels1, kernel_size1)\n",
    "print(result_comparison1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "input_tensor2 = np.random.rand(1, 1, 2, 2)  \n",
    "in_channels2 = 1\n",
    "out_channels2 = 3\n",
    "kernel_size2 = 2\n",
    "result_comparison2 = compare_with_torch(input_tensor2, in_channels2, out_channels2, kernel_size2)\n",
    "print(result_comparison2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "input_tensor3 = np.random.rand(1, 2, 3, 3) \n",
    "in_channels3 = 2\n",
    "out_channels3 = 2\n",
    "kernel_size3 = 2\n",
    "result_comparison3 = compare_with_torch(input_tensor3, in_channels3, out_channels3, kernel_size3)\n",
    "print(result_comparison3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
